{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khatana706/DATA-SCIENCE/blob/train/Copy_of_05_01_2021_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Eo8CMmSPvp",
        "outputId": "9fef66d3-88c7-465f-f857-746a714a54d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQxLG4UTW9z6",
        "outputId": "42266812-9c53-4c85-919d-788c95e9c8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/darknet\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/My Drive/darknet\n",
        "!pip install -q yolov4==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH3Fz1oZSaAa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from yolov4.tf import YOLOv4\n",
        "from PIL import Image\n",
        "from PIL.Image import fromarray as fa\n",
        "from IPython.display import clear_output\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from time import sleep\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUle2uGbL5hZ"
      },
      "outputs": [],
      "source": [
        "folder = \"accessories_all_together_human\"\n",
        "model = \"accessories_all_together_human_tiny_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYOG7bv3ihJN"
      },
      "outputs": [],
      "source": [
        "if \"gdrive\" not in folder:\n",
        "    folder = \"/gdrive/MyDrive/\"+folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoMEXFuZVLWx"
      },
      "outputs": [],
      "source": [
        "def get_files(folder_path):\n",
        "    files = listdir(folder_path)\n",
        "    valid_path = None\n",
        "    name_path = None\n",
        "    weight_path = None\n",
        "    for i in files:\n",
        "        if \"valid.txt\" in i:\n",
        "            valid_path = join(folder_path, i)\n",
        "        elif \"obj.name\" in i:\n",
        "            name_path = join(folder_path, i)\n",
        "        elif \"best.weights\" in i:\n",
        "            weight_path = join(folder_path, i)\n",
        "    return valid_path, name_path, weight_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFc2beQ_VuZM",
        "outputId": "64f36f0b-80bd-4bce-b6d3-9bc46863c27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid file path selected\n",
            "obj.name file path selected\n",
            "Best weight file selected.\n"
          ]
        }
      ],
      "source": [
        "valid_path, name_path, weight_path = get_files(model)\n",
        "valid_, name_, _ = get_files(folder)\n",
        "\n",
        "if valid_path == None:\n",
        "    if valid_ ==None:\n",
        "        print(\"Valid file path not found\")\n",
        "    else:\n",
        "        valid_path = valid_\n",
        "        print(\"Valid file path selected\")\n",
        "else:\n",
        "    print(\"Valid file path selected\")\n",
        "\n",
        "if name_path == None:\n",
        "    if name_ ==None:\n",
        "        print(\"obj.name file path not found\")\n",
        "    else:\n",
        "        name_path = name_\n",
        "        shutil.copy(name_, join(model, \"obj.names\"))\n",
        "        print(\"obj.name file path selected\")\n",
        "else:\n",
        "    print(\"obj.name file path selected\")\n",
        "\n",
        "if weight_path==None:\n",
        "    print(\"Best weight file cannot be found.\")\n",
        "else:\n",
        "    print(\"Best weight file selected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOgDUFD9aOVP",
        "outputId": "1e7ab7cd-8176-4033-8e9f-fa3336ba43f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images found: 472\n"
          ]
        }
      ],
      "source": [
        "#run this for getting paths of images used for training\n",
        "f=open(valid_path,\"r\")\n",
        "paths=f.read()\n",
        "f.close()\n",
        "paths=paths.split('\\n')\n",
        "shuffle(paths)\n",
        "print(\"Total number of images found:\",len(paths))\n",
        "image_paths = []\n",
        "for i in paths:\n",
        "    if \"gdrive\" not in i:\n",
        "        nm = \"/gdrive/MyDrive/\"+i[3:]\n",
        "        image_paths.append(nm)\n",
        "    else:\n",
        "        image_paths.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPS8DU98Zqvy"
      },
      "outputs": [],
      "source": [
        "# import glob\n",
        "# f1=[]\n",
        "# for filename in glob.iglob(folder + '/' + '**/*.jpg', recursive=True):\n",
        "#     f1.append(filename)\n",
        "# len(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiy7JMHzls7v",
        "outputId": "61cbd686-fdca-4b44-bd16-a3a30c031ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "0: scarfs: 12\n",
            "1: wallet: 13\n",
            "2: jhumkas: 7\n",
            "3: nose_ring: 9\n",
            "4: fanny: 7\n",
            "5: mang_tikka: 11\n",
            "6: nose_pin: 9\n",
            "7: wide: 11\n",
            "8: tobacco_purses: 9\n",
            "9: chandelier-earings: 15\n",
            "10: shoulder_bag: 6\n",
            "11: sunglasses: 7\n",
            "12: waist chain: 9\n",
            "13: statement_ring: 8\n",
            "14: snood: 12\n",
            "15: hand_bag: 17\n",
            "16: bangle: 10\n",
            "17: tote: 11\n",
            "18: travel: 6\n",
            "19: hat: 14\n",
            "20: beanie: 9\n",
            "21: beret: 7\n",
            "22: brooch: 9\n",
            "23: rings: 25\n",
            "24: chokar: 9\n",
            "25: kalangi: 14\n",
            "26: turban: 17\n",
            "27: briefcase: 6\n",
            "28: passa: 3\n",
            "29: pocket_square: 13\n",
            "30: zipper: 14\n",
            "31: chains: 11\n",
            "32: bracelet: 13\n",
            "33: sports: 13\n",
            "34: folder: 13\n",
            "35: cap: 11\n",
            "36: makeup_bag: 10\n",
            "37: dupatta: 6\n",
            "38: anklet: 7\n",
            "39: necklace: 9\n",
            "40: eyeglasses: 11\n",
            "41: drawstring: 8\n",
            "42: watch: 5\n",
            "43: kada: 8\n",
            "44: earring: 9\n",
            "45: phone_case: 11\n",
            "46: clutch: 13\n",
            "47: slim: 5\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "a=['scarfs', 'wallet', 'jhumkas', 'nose_ring', 'fanny', 'mang_tikka', 'nose_pin', 'wide', 'tobacco_purses', 'chandelier-earings', 'shoulder_bag', 'sunglasses',\n",
        "   'waist chain', 'statement_ring', 'snood', 'hand_bag', 'bangle', 'tote', 'travel', 'hat', 'beanie', 'beret', 'brooch', 'rings', 'chokar', 'kalangi', 'turban',\n",
        "   'briefcase', 'passa', 'pocket_square', 'zipper', 'chains', 'bracelet', 'sports', 'folder', 'cap', 'makeup_bag', 'dupatta', 'anklet', 'necklace', 'eyeglasses',\n",
        "   'drawstring', 'watch', 'kada', 'earring', 'phone_case', 'clutch', 'slim']\n",
        "print(len(a))\n",
        "ind=0\n",
        "for i in a:\n",
        "  c=0\n",
        "  for j in image_paths:\n",
        "    if i in j:\n",
        "      c+=1\n",
        "  print('{}: {}: {}'.format(ind,i,c))\n",
        "  ind=ind+1\n",
        "i_p=[]\n",
        "for j in image_paths:\n",
        "  if a[8] in j:\n",
        "    i_p.append(j)\n",
        "image_paths=i_p\n",
        "print(len(image_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhexm27CaLkt"
      },
      "outputs": [],
      "source": [
        "yolo = YOLOv4(tiny=(\"tiny\" in model))\n",
        "yolo.classes = name_path\n",
        "yolo.make_model()\n",
        "yolo.load_weights(weight_path, weights_type=\"yolo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgK7UQeufPNo"
      },
      "outputs": [],
      "source": [
        "def max_depth(folder:str):\n",
        "    tmp = sorted(listdir(folder))\n",
        "    mx = 0\n",
        "    for i in tmp:\n",
        "        if \".\" not in i:\n",
        "            mx = max(mx, 1+max_depth(join(folder, i)))\n",
        "    return mx\n",
        "# max_depth(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A819H8KbaLm"
      },
      "outputs": [],
      "source": [
        "classDict={}\n",
        "count=0\n",
        "for imgpath in image_paths:\n",
        "    count+=1\n",
        "    try:\n",
        "        original_image = cv2.imread(imgpath)\n",
        "        resized_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    except:\n",
        "        print(\"Error occured for\", imgpath)\n",
        "        input(\"press any key\")\n",
        "        clear_output()\n",
        "        continue\n",
        "    resized_image = yolo.resize_image(resized_image)\n",
        "    resized_image = resized_image / 255\n",
        "    input_data = resized_image[np.newaxis].astype(np.float32)\n",
        "    candidates = yolo.model.predict(input_data)\n",
        "\n",
        "    _candidates = []\n",
        "    for candidate in candidates:\n",
        "        batch_size = candidate.shape[0]\n",
        "        grid_size = candidate.shape[1]\n",
        "        _candidates.append(          \n",
        "            tf.reshape(\n",
        "                candidate, shape=(1, grid_size * grid_size * 3, -1)\n",
        "            )\n",
        "        )\n",
        "    candidates = np.concatenate(_candidates, axis=1)\n",
        "\n",
        "    pred_bboxes = yolo.candidates_to_pred_bboxes(candidates[0],iou_threshold=0.5,score_threshold=0.2)\n",
        "    # print(len(pred_bboxes))\n",
        "    pred_bboxes = yolo.fit_pred_bboxes_to_original(\n",
        "        pred_bboxes, original_image.shape\n",
        "    )\n",
        "    img=Image.open(imgpath)\n",
        "    width, height = img.size\n",
        "    new_height=800\n",
        "    new_width=int(width*(new_height/height))\n",
        "    img=img.resize((new_width,new_height))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.imshow(img, interpolation='nearest')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(count)\n",
        "    predicted=list([yolo.classes[i[-2]] for i in pred_bboxes[:5]])\n",
        "    print(\"Prediction:\",predicted)\n",
        "    pathToImage=imgpath.split('/')[3:-1]\n",
        "    print(\" -> \".join(pathToImage))\n",
        "    print(\"-\\tPress 'd' if data mismatch is there.\\n-\\tPress 'n' if prediction is wrong.\\n-\\tPress any key if prediction is right.\")\n",
        "    sleep(3)\n",
        "    response=input()\n",
        "    if \"men\" in pathToImage[-1].lower():\n",
        "        imgBelong=pathToImage[-2]\n",
        "        imgApparel=pathToImage[-1]\n",
        "    else:\n",
        "        imgBelong=pathToImage[-1]\n",
        "        imgApparel=pathToImage[-2]\n",
        "\n",
        "    if imgApparel not in classDict.keys():\n",
        "        classDict[imgApparel]={}\n",
        "    if imgBelong not in classDict[imgApparel].keys():\n",
        "        classDict[imgApparel][imgBelong]={\"correct\":0,\"total\":0,\"mismatch\":0}\n",
        "    if response=='d':\n",
        "        classDict[imgApparel][imgBelong][\"mismatch\"]+=1\n",
        "        classDict[imgApparel][imgBelong][\"total\"]+=1\n",
        "        classDict[imgApparel][imgBelong][\"correct\"]+=1\n",
        "    elif response=='n':\n",
        "        classDict[imgApparel][imgBelong][\"total\"]+=1\n",
        "    else:\n",
        "        classDict[imgApparel][imgBelong][\"total\"]+=1\n",
        "        classDict[imgApparel][imgBelong][\"correct\"]+=1\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9y3KpqlcGEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e9f62c-763c-451e-90e8-83f11754a826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " accessories_all_together_human\n",
            "    tobacco_purses --> 100.0 %\n"
          ]
        }
      ],
      "source": [
        "for i in classDict.keys():\n",
        "    print(\"\\n\",i)\n",
        "    for j in classDict[i].keys():\n",
        "        if classDict[i][j][\"total\"]==0:\n",
        "            print(\"\\tNo images were there for\",i)\n",
        "        else:\n",
        "            print(\" \"*4+j.ljust(10,\" \"),\"-->\",classDict[i][j][\"correct\"]/classDict[i][j][\"total\"]*100,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po56irc2dCaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd210601-3966-4075-eda6-89696a0b3fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Mismatch Count\n",
            "\n",
            "\n",
            " accessories_all_together_human\n",
            "     tobacco_purses       --> 0 / 9\n"
          ]
        }
      ],
      "source": [
        "print(\"Data Mismatch Count\\n\")\n",
        "for i in classDict.keys():\n",
        "    print(\"\\n\",i)\n",
        "    for j in classDict[i].keys():\n",
        "        print(\" \"*4,j.ljust(20,\" \"),\"-->\",classDict[i][j][\"mismatch\"],\"/\",classDict[i][j][\"total\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKRRY-PtdFUu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of 05-01-2021-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}